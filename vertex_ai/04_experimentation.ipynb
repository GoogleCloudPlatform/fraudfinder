{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Fraudfinder - XGBoost Model Experimentation\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/ai-platform/notebooks/deploy-notebook?download_url=https://github.com/GoogleCloudPlatform/fraudfinder/raw/main/04_model_experimentation.ipynb\">\n",
    "       <img src=\"https://www.gstatic.com/cloud/images/navigation/vertex-ai.svg\" alt=\"Google Cloud Notebooks\">Open in Cloud Notebook\n",
    "    </a>\n",
    "  </td> \n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/fraudfinder/blob/main/04_model_experimentation.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Open in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/fraudfinder/blob/main/04_model_experimentation.ipynb\">\n",
    "        <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "[Fraudfinder](https://github.com/googlecloudplatform/fraudfinder) is a series of labs on how to build a real-time fraud detection system on Google Cloud. Throughout the Fraudfinder labs, you will learn how to read historical bank transaction data stored in data warehouse, read from a live stream of new transactions, perform exploratory data analysis (EDA), do feature engineering, ingest features into a feature store, train a model using feature store, register your model in a model registry, evaluate your model, deploy your model to an endpoint, do real-time inference on your model with feature store, and monitor your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "### Objective\n",
    "\n",
    "This notebook shows how to pull features from Feature Store for training, run data exploratory analysis on features, build a machine learning model locally, experiment with various hyperparameters, evaluate the model and deloy it to a Vertex AI endpoint. \n",
    "\n",
    "This lab uses the following Google Cloud services and resources:\n",
    "\n",
    "- [Vertex AI](https://cloud.google.com/vertex-ai/)\n",
    "- [BigQuery](https://cloud.google.com/bigquery/)\n",
    "\n",
    "Steps performed in this notebook:\n",
    "\n",
    "- Use a Feature Store to pull training data\n",
    "- Do some exploratory analysis on the extracted data\n",
    "- Train the model and track the results using Vertex AI Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "* Vertex AI\n",
    "* BigQuery\n",
    "\n",
    "Learn about [Vertex AI\n",
    "pricing](https://cloud.google.com/vertex-ai/pricing), [BigQuery pricing](https://cloud.google.com/bigquery/pricing) and use the [Pricing\n",
    "Calculator](https://cloud.google.com/products/calculator/)\n",
    "to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load configuration settings from the setup notebook\n",
    "\n",
    "Set the constants used in this notebook and load the config settings from the `00_environment_setup.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCP_PROJECTS = !gcloud config get-value project\n",
    "PROJECT_ID = GCP_PROJECTS[0]\n",
    "BUCKET_NAME = f\"{PROJECT_ID}-fraudfinder\"\n",
    "config = !gsutil cat gs://{BUCKET_NAME}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoEqT2Y4DJmf"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pRUOFELefqf1"
   },
   "outputs": [],
   "source": [
    "# General\n",
    "import os\n",
    "import sys\n",
    "from typing import Union, List\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "\n",
    "# Feature Store\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud.aiplatform import Featurestore, EntityType, Feature\n",
    "\n",
    "# Data Preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Model Training\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "TIMESTAMP = str(int(time.time()))\n",
    "DATA_DIR = os.path.join(os.pardir, \"data\")\n",
    "DATA_URI = f\"gs://{BUCKET_NAME}/data\"\n",
    "TRAIN_DATA_URI = f\"{DATA_URI}/train\"\n",
    "\n",
    "# Feature Store\n",
    "START_DATE_TRAIN = (datetime.today() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "END_DATE_TRAIN = (datetime.today() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "CUSTOMER_ENTITY = \"customer\"\n",
    "TERMINAL_ENTITY = \"terminal\"\n",
    "SERVING_FEATURE_IDS = {CUSTOMER_ENTITY: [\"*\"], TERMINAL_ENTITY: [\"*\"]}\n",
    "READ_INSTANCES_TABLE = f\"ground_truth_{END_DATE_TRAIN}\"\n",
    "READ_INSTANCES_URI = f\"bq://{PROJECT_ID}.tx.{READ_INSTANCES_TABLE}\"\n",
    "\n",
    "# Training\n",
    "COLUMNS_IGNORE = [\"terminal_id\", \"customer_id\", \"entity_type_event\", \"entity_type_customer\", \"entity_type_terminal\"]\n",
    "TARGET = \"tx_fraud\"\n",
    "\n",
    "# Custom Training\n",
    "MODEL_NAME=f\"fraudfinder_xgb_model_expr-{ID}-{TIMESTAMP}\"\n",
    "\n",
    "## Experiment\n",
    "EXPERIMENT_NAME = \"ff-experiment-\" + TIMESTAMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoEqT2Y4DJmf"
   },
   "source": [
    "### Initialize clients\n",
    "Next you have to initialize the [Vertex AI SDK](https://cloud.google.com/vertex-ai/docs/start/use-vertex-ai-python-sdk) and the Python BigQuery Client for your project, region and corresponding bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_client = bigquery.Client(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_NAME, \n",
    "               experiment=EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "Next you will create a helper function for sending queries to BigQuery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bq_query(sql: str) -> Union[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Run a BigQuery query and return the job ID or result as a DataFrame\n",
    "    Args:\n",
    "        sql: SQL query, as a string, to execute in BigQuery\n",
    "    Returns:\n",
    "        df: DataFrame of results from query,  or error, if any\n",
    "    \"\"\"\n",
    "\n",
    "    bq_client = bigquery.Client()\n",
    "\n",
    "    # Try dry run before executing query to catch any errors\n",
    "    job_config = bigquery.QueryJobConfig(dry_run=True, use_query_cache=False)\n",
    "    bq_client.query(sql, job_config=job_config)\n",
    "\n",
    "    # If dry run succeeds without errors, proceed to run query\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    client_result = bq_client.query(sql, job_config=job_config)\n",
    "\n",
    "    job_id = client_result.job_id\n",
    "\n",
    "    # Wait for query/job to finish running. then get & return data frame\n",
    "    df = client_result.result().to_arrow().to_pandas()\n",
    "    print(f\"Finished job_id: {job_id}\")\n",
    "    return df\n",
    "\n",
    "def create_gcs_dataset(client,\n",
    "                       display_name: str,\n",
    "                       gcs_source: Union[str, List[str]]):\n",
    "    \"\"\"\n",
    "    A function to create a Vertex AI Dataset resource\n",
    "    Args:\n",
    "        client: VertexAI Client instance\n",
    "        display_name: The name of Vertex AI Dataset resource\n",
    "        gcs_source: The uri of data on the bucket\n",
    "    Returns:\n",
    "        VertexAI Dataset resource\n",
    "    \"\"\"\n",
    "    dataset = client.TabularDataset.create(\n",
    "        display_name=display_name, gcs_source=gcs_source,\n",
    "    )\n",
    "\n",
    "    dataset.wait()\n",
    "    return dataset\n",
    "\n",
    "def preprocess(df):\n",
    "    \"\"\"Converts categorical features to numeric. Removes unused columns.\n",
    "    Args:\n",
    "      df: Pandas df with raw data\n",
    "    Returns:\n",
    "      df with preprocessed data\n",
    "    \"\"\"\n",
    "    df = df.drop(columns=UNUSED_COLUMNS)\n",
    "\n",
    "    # Drop rows with NaN\"s\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Convert integer valued (numeric) columns to floating point\n",
    "    numeric_columns = df.select_dtypes([\"int32\", \"float32\", \"float64\"]).columns\n",
    "    df[numeric_columns] = df[numeric_columns].astype(\"float32\")\n",
    "\n",
    "    dummy_columns = list(df.dtypes[df.dtypes == \"category\"].index)\n",
    "    df = pd.get_dummies(df, columns=dummy_columns)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching feature values for model training\n",
    "\n",
    "To fetch training data, we have to specify the following inputs to batch serving:\n",
    "\n",
    "- a file containing a \"query\", with the entities and timestamps for each label\n",
    "- a list of features to fetch values for\n",
    "- the destination location and format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read-instance list\n",
    "\n",
    "In our case, we need a csv file with content formatted like the table below:\n",
    "\n",
    "|customer                     |terminal|timestamp                                    |\n",
    "|-----------------------------|--------|---------------------------------------------|\n",
    "|xxx3859                         |xxx8811    |2021-07-07 00:01:10 UTC                      |\n",
    "|xxx4165                         |xxx8810    |2021-07-07 00:01:55 UTC                      |\n",
    "|xxx2289                         |xxx2081    |2021-07-07 00:02:12 UTC                      |\n",
    "|xxx3227                         |xxx3011    |2021-07-07 00:03:23 UTC                      |\n",
    "|xxx2819                         |xxx6263    |2021-07-07 00:05:30 UTC                      |\n",
    "\n",
    "where the column names are the name of entities in Feature Store and the timestamps represents the time an event occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_instances_query = f\"\"\"\n",
    "    SELECT\n",
    "        raw_tx.TX_TS AS timestamp,\n",
    "        raw_tx.CUSTOMER_ID AS customer,\n",
    "        raw_tx.TERMINAL_ID AS terminal,\n",
    "        raw_tx.TX_AMOUNT AS tx_amount,\n",
    "        raw_lb.TX_FRAUD AS tx_fraud,\n",
    "    FROM \n",
    "        tx.tx as raw_tx\n",
    "    LEFT JOIN \n",
    "        tx.txlabels as raw_lb\n",
    "    ON raw_tx.TX_ID = raw_lb.TX_ID\n",
    "    WHERE\n",
    "        DATE(raw_tx.TX_TS) = \"{START_DATE_TRAIN}\";\n",
    "\"\"\"\n",
    "print(read_instances_query)\n",
    "\n",
    "query_df = run_bq_query(read_instances_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check our read instance list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Feature Store\n",
    "Now you can get the feature store ID so that we can fetch a batch of training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_feature_store = Featurestore(FEATURESTORE_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export a training sample of data to a pandas dataframe.\n",
    "First you need to fetch a batch of data. We will use this data to train a custom model. We will fetch a batch of data and create a Pandas dataframe. The dataframe makes it easier to inspect the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = ff_feature_store.batch_serve_to_df(\n",
    "    serving_feature_ids=SERVING_FEATURE_IDS,\n",
    "    read_instances_df=query_df,\n",
    "    pass_through_fields = ['tx_fraud','tx_amount']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration\n",
    "Here you will use a subset of data for data exploration to get a better understanding of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine the label distibution\n",
    "With Fraud detection we often have a challenge with the distribution of our target value. Fraud vs non-Fraud can be skewed. We want to understand the distribution. Lets create a plot and do an actual count of the values (fraud vs non-fraud)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"fraud_reported distribution\")\n",
    "sns.countplot(x=\"tx_fraud\", data=sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sample_df.tx_fraud.value_counts()/sample_df.shape[0])*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the data is imbalanced. We will fix this later in this notebook before building the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a better understanding of the feature distributions using histograms\n",
    "Now you can do the same for the input features. It's good to plot the distributions of our features to get a better understanding of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [ \"tx_amount\", \"customer_id_nb_tx_7day_window\", \"customer_id_nb_tx_14day_window\",\n",
    "             \"customer_id_nb_tx_1day_window\", \"customer_id_avg_amount_7day_window\", \"customer_id_avg_amount_14day_window\",\n",
    "             \"customer_id_avg_amount_1day_window\", \"terminal_id_risk_7day_window\", \"terminal_id_risk_14day_window\",\n",
    "             \"terminal_id_risk_1day_window\", \"terminal_id_nb_tx_14day_window\", \"terminal_id_nb_tx_1day_window\",\n",
    "            \"terminal_id_nb_tx_7day_window\"]\n",
    "\n",
    "sample_df[features].hist(figsize = (20, 10), grid=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze the relationship between features and ```tx_fraud```\n",
    "Now you can also look at the relationship between our target and input features. A good way to do this is creating a correlation heatmap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.heatmap(sample_df[sample_df.columns.difference(COLUMNS_IGNORE)].corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some Observations**\n",
    "\n",
    "Based on this simple exploratory data analysis (EDA) you can conclude:\n",
    "\n",
    "- The sample data is unbalanced.\n",
    "- You can probably remove some of the features with little predictive value.\n",
    "- You might want to extract subsets of the timestamp into separate features such as day, week, night, etc. (i.e. calculate some time-based embeddings).\n",
    "- You may want to do some variable selection.\n",
    "- You'll might need to scale some variables.\n",
    "\n",
    "## Builing a custom fraud detection model\n",
    "\n",
    "### Fixing an imbalanced dataset\n",
    "In the real world, we need to deal with imbalance in our dataset. For example, we might randomly delete some of the non-fraudulent transcations in order to approximately match the number of fraudulent transactions. This technique is called undersampling. \n",
    "\n",
    "For this workshop, we will skip the data balance process, because our sample data is small and further reduction will compromise the quality of our results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_df = sample_df.sample(frac=1,random_state=4)\n",
    "fraud_df = shuffled_df.loc[shuffled_df[\"tx_fraud\"] == 1]\n",
    "non_fraud_df = shuffled_df.loc[shuffled_df[\"tx_fraud\"] == 0].sample(n=fraud_df.shape[0],random_state=42)\n",
    "balanced_df = pd.concat([fraud_df, non_fraud_df])\n",
    "(balanced_df.tx_fraud.value_counts()/balanced_df.shape[0])*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "In this section, we will train a model using the xgboost algorithm. Typically, to perform training, you might want to use a Vertex AI traning pipeline, however, as we are still experimenting, we simply use the xgboost package interactively to train our model in this notebook. \n",
    "\n",
    "#### Why XGBoost?\n",
    "Extreme gradient-boosted (XGBoost) algorithm is a ML algorithm based on ensembles of decision trees, that works well with imbalanced data, handleing missing values, and can speed up through parallel-processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing datasets\n",
    "In the following cell, we split our data into training, test, and validation sets. Training data is the primary source of input for training the ML algorithm. Validation data is for determining our progress after each epoch or iteration of our training loop. Test data is data the model has never seen before and is used to assess model quality at the end of the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training variables\n",
    "LABEL_COLUMN = \"tx_fraud\"\n",
    "UNUSED_COLUMNS = [\"timestamp\",\"entity_type_customer\",\"entity_type_terminal\"]\n",
    "NA_VALUES = [\"NA\", \".\"]\n",
    "\n",
    "df_dataset = balanced_df\n",
    "df_train, df_test, df_val = np.split(df_dataset.sample(frac=1, random_state=42), [int(.6*len(df_dataset)), int(.8*len(df_dataset))])\n",
    "\n",
    "#training set\n",
    "preprocessed_train_Data = preprocess(df_dataset)\n",
    "x_train = preprocessed_train_Data[preprocessed_train_Data.columns.drop(LABEL_COLUMN).to_list()].values\n",
    "y_train = preprocessed_train_Data.loc[:,LABEL_COLUMN].astype(int)\n",
    "\n",
    "#validation set\n",
    "preprocessed_val_Data = preprocess(df_val)\n",
    "x_val = preprocessed_val_Data[preprocessed_val_Data.columns.drop(LABEL_COLUMN).to_list()].values\n",
    "y_val = preprocessed_val_Data.loc[:,LABEL_COLUMN].astype(int)\n",
    "\n",
    "#test set\n",
    "preprocessed_test_Data = preprocess(df_test)\n",
    "x_test = preprocessed_test_Data[preprocessed_test_Data.columns.drop(LABEL_COLUMN).to_list()].values\n",
    "y_test = preprocessed_test_Data.loc[:,LABEL_COLUMN].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Training the model\n",
    "Before training the XGBoost model, you can set some of the hyperparameters, which can help us with improving the model performance. We would advise you to use [Vertex AI Vizier](https://cloud.google.com/vertex-ai/docs/vizier/overview) to help with hyperparameter tuning. However, in this notebook, for the sake of simplicity and expedience, we specify these hyperparemeters manually and randomly. \n",
    "\n",
    "- Eta: A regularization parameter to reduce feature weights in each boosting step. \n",
    "- Gamma: A regularization parameter for tree pruning.\n",
    "- Maximum depth of a tree. Increasing this value will make the model more complex and more likely to overfit. \n",
    "\n",
    "\n",
    "For more information about parameters check [this document](https://xgboost.readthedocs.io/en/stable/parameter.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [\n",
    "    {\"eta\": 0.2, \"gamma\": 0.0, \"max_depth\": 4},\n",
    "    {\"eta\": 0.2, \"gamma\": 0.0, \"max_depth\": 5},\n",
    "    {\"eta\": 0.2, \"gamma\": 0.1, \"max_depth\": 4},\n",
    "    {\"eta\": 0.2, \"gamma\": 0.1, \"max_depth\": 5},\n",
    "    {\"eta\": 0.3, \"gamma\": 0.0, \"max_depth\": 4},\n",
    "    {\"eta\": 0.3, \"gamma\": 0.0, \"max_depth\": 5},\n",
    "    {\"eta\": 0.3, \"gamma\": 0.1, \"max_depth\": 4},\n",
    "    {\"eta\": 0.3, \"gamma\": 0.1, \"max_depth\": 5},\n",
    "]\n",
    "\n",
    "models={}\n",
    "for i, params in enumerate(parameters):\n",
    "    run_name=f\"fd-xgboost-local-run-{i}\"\n",
    "    print(run_name)\n",
    "    vertex_ai.start_run(run=run_name)\n",
    "    vertex_ai.log_params(params)\n",
    "    model =  xgb.XGBClassifier( objective=\"reg:logistic\", max_depth = params[\"max_depth\"], gamma = params[\"gamma\"], eta = params[\"eta\"], use_label_encoder=False)\n",
    "    model.fit(x_train, y_train)\n",
    "    models[run_name] = model\n",
    "    y_pred_proba = model.predict_proba(x_val)[:, 1]\n",
    "    y_pred = model.predict(x_val)\n",
    "    acc_score = accuracy_score(y_val, y_pred)\n",
    "    val_f1_score = f1_score(y_val, y_pred, average=\"weighted\")\n",
    "    vertex_ai.log_metrics({\"acc_score\": acc_score, \"f1score\": val_f1_score})\n",
    "    vertex_ai.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that XGBoost usually performs well on imbalanced datasets. But lets also try another algorithm, such as logistic regression, to see how various runs looks like in experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [\n",
    "    {\"solver\": \"lbfgs\", \"penalty\": \"none\"},\n",
    "    {\"solver\": \"lbfgs\", \"penalty\": \"l2\"},\n",
    "    {\"solver\": \"liblinear\", \"penalty\": \"l2\"},\n",
    "    {\"solver\": \"liblinear\", \"penalty\": \"l1\"},\n",
    "]\n",
    "\n",
    "for i, params in enumerate(parameters):\n",
    "    run_name=f\"fd-logisticreg-local-run-{i}\"\n",
    "    print(run_name)\n",
    "    vertex_ai.start_run(run=run_name)\n",
    "    vertex_ai.log_params(params)\n",
    "    clf = LogisticRegression(random_state=0, penalty=params[\"penalty\"], solver = params[\"solver\"]).fit(x_train, y_train.array)\n",
    "    y_pred = clf.predict(x_val[:, :])\n",
    "    clf.predict_proba(x_val[:2, :])\n",
    "    models[run_name] = clf\n",
    "    acc_score = clf.score(x_val, y_val)\n",
    "    val_f1_score = f1_score(y_val, y_pred, average=\"weighted\")\n",
    "    vertex_ai.log_metrics({\"acc_score\": acc_score, \"f1score\": val_f1_score})\n",
    "    vertex_ai.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1PqKxlpOZa2"
   },
   "source": [
    "We can also extract all parameters and metrics associated with any experiment into a dataframe for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jbRf1WoH_vbY"
   },
   "outputs": [],
   "source": [
    "experiment_df = vertex_ai.get_experiment_df()\n",
    "experiment_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F19_5lw0MqXv"
   },
   "source": [
    "Also we can visualize experiments using the Cloud Console. Run the following cell to get the URL of [Vertex AI Experiments](https://cloud.google.com/vertex-ai/docs/experiments/intro-vertex-ai-experiments) for your project. You can use follow the URL to see your results in the Cloud Console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GmN9vE9pqqzt"
   },
   "outputs": [],
   "source": [
    "print(\"Vertex AI Experiments:\")\n",
    "print(\n",
    "    f\"https://console.cloud.google.com/ai/platform/experiments/experiments?folder=&organizationId=&project={PROJECT_ID}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model\n",
    "Now that we have run our experiments, lets choose one of the experiments, and use `xgboost.Booster` `save_model` method to export the model to a local file named `model.bst`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = \"../models\"\n",
    "!sudo mkdir -p -m 777 {model_directory}\n",
    "\n",
    "model = models[\"fd-xgboost-local-run-0\"]\n",
    "artifact_filename = \"model.bst\"\n",
    "model_path = os.path.join(model_directory, artifact_filename)\n",
    "model.save_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Let's first test the model locally on your testset, to get predicted labels and an F1 score, which is an aggregation of the model's precision and recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb.Booster()  # init model\n",
    "bst.load_model(model_path) \n",
    "xgtest = xgb.DMatrix(x_test)\n",
    "y_pred_prob = bst.predict(xgtest)\n",
    "y_pred = y_pred_prob.round().astype(int)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(y_test.values, y_pred, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision to convert a predicted probability into a fraudulant/non-fradulant class label is determined by a discrimination threshold, which uses a default value of 0.5. That is, a transaction is predicted as non-fraudulant (class 0) if the probability is under 0.5, and fraudulant (class 1) if it is equal to or greater than 0.5. This threshold determines the True Positive, False Pasitive, True Negative, and False Negative results which are typically used in confusion matrix, precision, recall, and F1-score, all of which are used as accuracy metrics for a classification model.\n",
    "\n",
    "You might get different TP and FP rates if you change this threshold, especially if your data is unbalanced. By fine-tuning this threshold, you might find a value that leads to near optimal model performance, based on your business tolerance for accepting the cost of FP or FN cases. In the following cell we calculate the confusion matrix for different discrimination thresholds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,5, figsize=(15,4))\n",
    "     \n",
    "for n, ax in enumerate(axes.flat):\n",
    "    threshold =  (n+1)/10\n",
    "    y_pred = (y_pred_prob > threshold).astype(int)\n",
    "    cfm = metrics.confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cfm, annot=True, cmap=\"Reds\", fmt=\"d\", ax=ax, cbar=False)\n",
    "    ax.title.set_text(\"Threshold=%.2f\" % threshold)\n",
    "  \n",
    "plt.subplots_adjust(hspace=0.4, wspace=0.8)\n",
    "plt.suptitle(\"Confusion Matrix for various thresholds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might get more insight into the optimal threshold by examining a Receiver Operator Characteristic (ROC) Curve. This will plot the true positive (TP) vs. false positive (FP) rates at different classification thresholds. Lowering the classification threshold classifies more items as positive, thus increasing both False Positives and True Positives. The following figure shows a typical ROC curve. Also, we graph the Area Under the Curve (AUC) which ranges in value from 0 to 1. A model whose predictions are 100% wrong has an AUC of 0.0; one whose predictions are 100% correct has an AUC of 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall_fscore_support(y_test.values, y_pred, average=\"weighted\")\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test.values, y_pred_prob)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "  \n",
    "plt.figure(figsize=(8, 6))\n",
    "# plot the roc curve for the model\n",
    "plt.plot(fpr, tpr, marker=\".\",label=\"xgboost: AUC = %.2f\" % auc)\n",
    "\n",
    "# generate general prediction (majority class)\n",
    "ns_probs = [0 for _ in range(len(y_test))]\n",
    "ns_fpr, ns_tpr, _ = metrics.roc_curve(y_test, ns_probs)\n",
    "ns_auc = metrics.auc(ns_fpr, ns_tpr)\n",
    "plt.plot(ns_fpr, ns_tpr, linestyle=\"--\", label=\"No Skill: AUC = %.2f\" % ns_auc)\n",
    "  \n",
    "plt.ylabel(\"TP rate\")\n",
    "plt.xlabel(\"FP rate\")\n",
    "  \n",
    "plt.legend(loc=4)\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what is the optimal threshold? As mentioned, this depends on the business use case, for example, if we believe the optimal threshold for our use case is  one that offers the highest TPR and minimum FPR, then we can calculate the optimal threshold as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal threshold value is: %.3f\" % thresholds[np.argmax(tpr - fpr)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we understand our dataset more deeply, have achieved good results with the XGBoost algorithm, and have fine-tuned model hyperparameters, let's turn our attention in the next notebook to transitioning this training process from an ad hoc approach to a more formal method.\n",
    "\n",
    "You can continue with the next Notebook: `04_model_training_xgboost_formalization.ipynb`."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "notebook_template.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m102"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
